{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files into numpy array and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data/MNIST/original/train-labels-idx1-ubyte', '../../data/MNIST/original/t10k-images-idx3-ubyte', '../../data/MNIST/original/t10k-labels-idx1-ubyte', '../../data/MNIST/original/train-images-idx3-ubyte']\n",
      "60000 labels with shape of (1,), Output shape: (60000, 1)\n",
      "60000 images with shape of (28, 28), Output shape: (60000, 1, 28, 28)\n",
      "10000 labels with shape of (1,), Output shape: (10000, 1)\n",
      "10000 images with shape of (28, 28), Output shape: (10000, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [4]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(\"../../data/MNIST/original/**\")\n",
    "assert (len(files)==4), \"4 Files are required\"\n",
    "print(files)\n",
    "\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def readImages(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        struct.unpack('>i',f.read(4))[0]\n",
    "        n_images = struct.unpack('>i',f.read(4))[0] \n",
    "        n_rows = struct.unpack('>i',f.read(4))[0]\n",
    "        n_cols = struct.unpack('>i',f.read(4))[0]\n",
    "        images = np.fromfile(f,dtype=np.uint8)\n",
    "    assert (n_images==images.shape[0]/n_cols/n_rows), \"Problem in reading the file. \\\n",
    "    The header of file does not match with its data\"\n",
    "    images = images.reshape(-1,1,n_rows,n_cols)\n",
    "    print(\"{n_i} images with shape of {shape}, Output shape: {o_sh}\".format(\n",
    "        n_i = n_images, shape = (n_rows, n_cols), o_sh=images.shape))\n",
    "    return images\n",
    "\n",
    "def readLables(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        struct.unpack('>i',f.read(4))[0]\n",
    "        n_labels = struct.unpack('>i',f.read(4))[0] \n",
    "        labels = np.fromfile(f,dtype=np.uint8)\n",
    "    assert (n_labels==labels.shape[0]), \"Problem in reading the file. \\\n",
    "    The header of file does not match with its data\"\n",
    "    labels = labels.reshape(n_labels,-1)\n",
    "    print(\"{n_i} labels with shape of {shape}, Output shape: {o_sh}\".format(\n",
    "        n_i = n_labels, shape = labels[0].shape, o_sh = labels.shape))\n",
    "    return labels\n",
    "\n",
    "train_labels=readLables(files[0])\n",
    "train_images=readImages(files[3])\n",
    "test_labels=readLables(files[2])\n",
    "test_images=readImages(files[1])\n",
    "\n",
    "idx = 15347\n",
    "plt.imshow(train_images[idx,0],cmap='gray')\n",
    "plt.show()\n",
    "print (\"label:\" ,train_labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr = transforms.Compose([transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5),(0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8aa8ed279aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/programming/anaconda3/envs/AI/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/programming/anaconda3/envs/AI/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/programming/anaconda3/envs/AI/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be PIL Image or ndarray. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "out = tr(train_images)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (AI)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
